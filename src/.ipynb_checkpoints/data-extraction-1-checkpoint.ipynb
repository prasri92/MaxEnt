{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ninad/anaconda3/envs/maxent/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2714: DtypeWarning: Columns (111) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'DUPERSID', u'PANEL', u'AGE1X', u'SEX', u'RACEAX', u'RACEBX',\n",
      "       u'RACEWX', u'RTHLTH1', u'RTHLTH2', u'RTHLTH3',\n",
      "       ...\n",
      "       u'perwt', u'netchange', u'sf0', u'ss0', u'sdif0', u'weight', u'age',\n",
      "       u'sdif38', u'sdif39', u'sdif40'],\n",
      "      dtype='object', length=942)\n",
      "('Total columns:', 942)\n"
     ]
    }
   ],
   "source": [
    "# Loading the big csv file (exported from the excel file)\n",
    "# All other pre-processing is done here\n",
    "# The \"cleaned\" csv files are then stored\n",
    "\n",
    "bigFilePath = '../data/2010-2014-allCol.csv'\n",
    "big_df = pd.read_csv(bigFilePath)\n",
    "col_list = big_df.columns\n",
    "print (col_list)\n",
    "print (\"Total columns:\",  len(col_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-3-d351eb936508>, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-d351eb936508>\"\u001b[0;36m, line \u001b[0;32m42\u001b[0m\n\u001b[0;31m    244 Externally Caused Injuries and Conditions\u001b[0m\n\u001b[0m                                                 \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "\"\"\" CCC codes for diseases enumerated in the MBA anaylis. Taken from Appendix C of Schmitt-thesis\n",
    "12 Cancer of Esophagus\n",
    "30 Cancer of Testis\n",
    "47 Other and Unspecified Benign Neoplasm\n",
    "48 Thyroid Disorders\n",
    "49 Diabetes Mellitus\n",
    "50 Diabetes Mellitus with Complications\n",
    "51 Other Endocrine Disorders\n",
    "52 Nutritional Deficiencies\n",
    "53 Lipid Metabolism Disorder\n",
    "86 Cataract\n",
    "91 Other Eye Disorders\n",
    "95 Other Nervous System Disorders\n",
    "96 Heart Valve Disorders\n",
    "98 Essential Hypertension\n",
    "100 Acute Myocardial Infarction\n",
    "101 Coronary Atherosclerosis and Other Heart Disease\n",
    "103 Pulmonary Heart Disease\n",
    "104 Other and Ill-Defined Heart Disease\n",
    "105 Conduction Disorders\n",
    "106 Cardiac Dysrhythmias\n",
    "110 Occlusion or Stenosis of Prevertebral Arteries\n",
    "111 Other and Ill-Defined Cerebrovascular Disease\n",
    "126 Other Upper Respiratory Infections\n",
    "127 Chronic Obstructive Pulmonary Disease and Bronchiectasis\n",
    "128 Asthma\n",
    "133 Other Lower Respiratory Disease\n",
    "134 Other Upper Respiratory Disease\n",
    "200 Other Skin Disorders\n",
    "202 Rheumatoid Arthritis and Related Disease\n",
    "203 Osteoarthritis\n",
    "204 Non Traumatic Joint Disorders\n",
    "205 Spondylosis; Intervertebral Disc Disorders; Other Back Problems\n",
    "211 Other Connective Tissue Disorders\n",
    "259 Unclassified CCC\n",
    "651 Anxiety Disorder\n",
    "657 Mood Disorder\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" Extra CCC codes that were missing\n",
    "232 Sprains and strains\n",
    "244 Externally Caused Injuries and Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = '12 30 47  48 49 50 51 52 53 86 91 95 96 98 100 101 103  104 105 106 \\\n",
    "    110 111 126 127 128 133 134 200 202 203 204 205 211 232 244 259 651 657'\n",
    "new_col_list = x.split()\n",
    "len(new_col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting relevant column numbers from the big list\n",
    "new_col_nums_fy = []  # First year data\n",
    "new_col_nums_sy = []  # Second year data\n",
    "fy_first = 332\n",
    "fy_last = 601\n",
    "sy_last = 872\n",
    "\n",
    "for dcode in new_col_list:\n",
    "    fycode = 'CCCfy' + dcode\n",
    "    sycode = 'CCCsy' + dcode    \n",
    "    for i in range(fy_first, sy_last+1):\n",
    "        if col_list[i] == fycode:\n",
    "            new_col_nums_fy.append(i)\n",
    "        elif col_list[i] == sycode:\n",
    "            new_col_nums_sy.append(i)\n",
    "\n",
    "# NOT NEEDED AT ALL!!!\n",
    "# CAN filter through the data-frame using just column ids\n",
    "\n",
    "fy_codes = []\n",
    "sy_codes = []\n",
    "for dcode in new_col_list: \n",
    "    fy = 'CCCfy' + dcode\n",
    "    fy_codes.append(fy)\n",
    "    sy = 'CCCsy' + dcode\n",
    "    sy_codes.append(sy)\n",
    "\n",
    "merge_codes = fy_codes + sy_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract from data frame using these code \n",
    "df_fy = big_df.filter(fy_codes, axis=1)\n",
    "df_sy = big_df.filter(sy_codes, axis=1)\n",
    "df_merge = big_df.filter(merge_codes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the shape of the three data frames:\n",
      "(67690, 38) (67690, 38) (67690, 76)\n"
     ]
    }
   ],
   "source": [
    "print \"Printing the shape of the three data frames:\"\n",
    "print df_fy.shape, df_sy.shape, df_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the shape of the three data frames after dropping the NaN rows:\n",
      "(41399, 38) (41399, 38) (41399, 76)\n"
     ]
    }
   ],
   "source": [
    "# # Drop the rows who have NaN in certain columns\n",
    "# df_fy_drp = df_fy.dropna()\n",
    "# df_sy_drp = df_sy.dropna()\n",
    "# df_merge_drp = df_merge.dropna()\n",
    "\n",
    "# print \"Printing the shape of the three data frames after dropping the NaN rows:\"\n",
    "# print df_fy_drp.shape, df_sy_drp.shape, df_merge_drp.shape\n",
    "\n",
    "# print \"Saving the cleaned data frames to csv files\"\n",
    "# fy_csv_file = '../data/test1-fy-dropna.csv'\n",
    "# sy_csv_file = '../data/test1-sy-dropna.csv'\n",
    "# merge_csv_file = '../data/test1-merge-dropna.csv'\n",
    "\n",
    "# df_fy.to_csv(fy_csv_file, encoding='utf-8', index=False)\n",
    "# df_sy.to_csv(sy_csv_file, encoding='utf-8', index=False)\n",
    "# df_merge.to_csv(merge_csv_file, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the shape of the three data frames after dropping the NaN rows:\n",
      "(67690, 38) (67690, 38) (67690, 76)\n"
     ]
    }
   ],
   "source": [
    "# Fill the rows who have NaN in certain columns\n",
    "df_fy = df_fy.fillna(int(0))\n",
    "df_sy = df_sy.fillna(int(0))\n",
    "df_merge = df_merge.fillna(int(0))\n",
    "\n",
    "print \"Printing the shape of the three data frames after dropping the NaN rows:\"\n",
    "print df_fy.shape, df_sy.shape, df_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Saving the cleaned data frames to csv files\"\n",
    "fy_csv_file = '../data/test1-fy-fillna.csv'\n",
    "sy_csv_file = '../data/test1-sy-fillna.csv'\n",
    "merge_csv_file = '../data/test1-merge-fillna.csv'\n",
    "\n",
    "df_fy.to_csv(fy_csv_file, encoding='utf-8', index=False)\n",
    "df_sy.to_csv(sy_csv_file, encoding='utf-8', index=False)\n",
    "df_merge.to_csv(merge_csv_file, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the toy-dataset\n",
    "filePath = '../data/Age50_DataExtract.csv'\n",
    "df = pd.read_csv(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['fyAGE', 'CCCfy98.1']\n",
    "df = df.drop(drop_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fy_list = col_list[:9]\n",
    "sy_list = col_list[9:]\n",
    "\n",
    "df_fy = df.filter(fy_list, axis=1)\n",
    "df_sy = df.filter(sy_list, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Saving the clean csv files\"\n",
    "\n",
    "fname_merge = '../data/Age50_DataExtract_merge.csv'\n",
    "fname_fy = '../data/Age50_DataExtract_fy.csv'\n",
    "fname_sy = '../data/Age50_DataExtract_sy.csv'\n",
    "\n",
    "df.to_csv(fname_merge, encoding='utf-8', index=False)\n",
    "df_fy.to_csv(fname_fy, encoding='utf-8', index=False)\n",
    "df_sy.to_csv(fname_sy, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tups = [tuple(x) for x in df.values]\n",
    "data_arr = np.asarray(tups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr\n",
    "data_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make multi valued discrete data into binary\n",
    "\n",
    "\n",
    "# converts column j to binary vec\n",
    "def convert_discrete_data(data, j):\n",
    "    # set of values\n",
    "    valset = set(data[:,j])\n",
    "    valdict = {}\n",
    "    count = 0\n",
    "    for i in valset:\n",
    "        valdict[i] = count\n",
    "        count += 1\n",
    "    \n",
    "    m = len(valset)\n",
    "    \n",
    "    # Now remap the data set\n",
    "    \n",
    "    N = data.shape[0]\n",
    "    \n",
    "    ndata = np.zeros((N,m))\n",
    "    \n",
    "    for i in range(N):\n",
    "        pos = valdict[data[i,j]]\n",
    "        ndata[i,pos] = 1 #one hot encoding\n",
    "    \n",
    "    new_arr = np.concatenate((data[:,:j], ndata, data[:,j+1:]), axis=1)\n",
    "    return new_arr\n",
    "                            \n",
    "\n",
    "\n",
    "nd = convert_discrete_data(data_arr,20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "These are the diseases under consideration for comparsion of L-measure and MBA for constraints to\n",
    "the maxent problem.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" CCC codes for diseases enumerated in the MBA anaylis. Taken from Appendix C of Schmitt-thesis\n",
    "12 Cancer of Esophagus\n",
    "30 Cancer of Testis\n",
    "47 Other and Unspecified Benign Neoplasm\n",
    "48 Thyroid Disorders\n",
    "49 Diabetes Mellitus\n",
    "50 Diabetes Mellitus with Complications\n",
    "51 Other Endocrine Disorders\n",
    "52 Nutritional Deficiencies\n",
    "53 Lipid Metabolism Disorder\n",
    "86 Cataract\n",
    "91 Other Eye Disorders\n",
    "95 Other Nervous System Disorders\n",
    "96 Heart Valve Disorders\n",
    "98 Essential Hypertension\n",
    "100 Acute Myocardial Infarction\n",
    "101 Coronary Atherosclerosis and Other Heart Disease\n",
    "103 Pulmonary Heart Disease\n",
    "104 Other and Ill-Defined Heart Disease\n",
    "105 Conduction Disorders\n",
    "106 Cardiac Dysrhythmias\n",
    "110 Occlusion or Stenosis of Prevertebral Arteries\n",
    "111 Other and Ill-Defined Cerebrovascular Disease\n",
    "126 Other Upper Respiratory Infections\n",
    "127 Chronic Obstructive Pulmonary Disease and Bronchiectasis\n",
    "128 Asthma\n",
    "133 Other Lower Respiratory Disease\n",
    "134 Other Upper Respiratory Disease\n",
    "200 Other Skin Disorders\n",
    "202 Rheumatoid Arthritis and Related Disease\n",
    "203 Osteoarthritis\n",
    "204 Non Traumatic Joint Disorders\n",
    "205 Spondylosis; Intervertebral Disc Disorders; Other Back Problems\n",
    "211 Other Connective Tissue Disorders\n",
    "259 Unclassified CCC\n",
    "651 Mood Disorder\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" Extra CCC codes that were missing\n",
    "232 Sprains and strains\n",
    "244 Externally Caused Injuries and Conditions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
