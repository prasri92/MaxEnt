{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['0', '1', '2', '3'], dtype='object')\n",
      "Total columns: 4\n"
     ]
    }
   ],
   "source": [
    "filePath = '../dataset/d50_4/synthetic_data_expt1.csv'\n",
    "df = pd.read_csv(filePath)\n",
    "col_list = df.columns\n",
    "print (col_list)\n",
    "print (\"Total columns:\",  len(col_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the cleaned data frames to csv files\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_fy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7d1a38368935>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmerge_csv_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../dataset/d50_4/test1-merge.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdf_fy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfy_csv_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mdf_sy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msy_csv_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdf_merge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerge_csv_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_fy' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Saving the cleaned data frames to csv files\")\n",
    "fy_csv_file = '../dataset/d50_4/test1-fy.csv'\n",
    "sy_csv_file = '../dataset/d50_4/test1-sy.csv'\n",
    "merge_csv_file = '../dataset/d50_4/test1-merge.csv'\n",
    "\n",
    "df_fy.to_csv(fy_csv_file, encoding='utf-8', index=False)\n",
    "df_sy.to_csv(sy_csv_file, encoding='utf-8', index=False)\n",
    "df_merge.to_csv(merge_csv_file, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0]\n",
      " [1 1 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 1]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [1 0 0 0]\n",
      " [0 0 0 0]]\n",
      "[[0 0 1 1]\n",
      " [1 1 0 1]\n",
      " [0 1 0 1]\n",
      " [1 0 1 1]\n",
      " [1 1 0 1]\n",
      " [0 1 0 0]\n",
      " [0 0 0 0]\n",
      " [1 1 1 0]\n",
      " [1 1 1 0]\n",
      " [1 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "def load_disease_data_perturb(filePath, prob):\n",
    "    \"\"\" Creates a numpy array from given csv file\n",
    "\n",
    "    Creates a pandas dataframe from the given csv file and then exports it to \n",
    "    a numpy ndarray. Also perfoms the check where any value > 0 is mapped to 1 \n",
    "    since it corresponds to a particular disease being prevalent.\n",
    "\n",
    "    Args:\n",
    "        filePath: Path to the csv file to load the disease data from\n",
    "        prob: perturbation probability for 0 to 1\n",
    "\n",
    "    Returns:\n",
    "        A binary (0-1) numpy ndarray with each row corresponding to a particular \n",
    "        person's disease prevalence data. \n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filePath)\n",
    "    tups = [tuple(x) for x in df.values]\n",
    "    data_arr = np.asarray(tups)\n",
    "    print(data_arr[:10])\n",
    "    # Map all positive values to 1 since any > 0 indicates the disease\n",
    "    data_arr[data_arr > 0] = 1\n",
    "    \n",
    "    p_mat = np.random.random(size=data_arr.shape)\n",
    "    p_idx = (p_mat <= prob)\n",
    "    data_arr[p_idx] = 1 # If there was 1 prev, no problem, but if there was a 0, map it to 1    \n",
    "    \n",
    "    return data_arr\n",
    "\n",
    "a = load_disease_data_perturb('../dataset/d50_4/synthetic_data_expt1.csv', 0.6)\n",
    "print(a[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randint(2, size=(34,15))\n",
    "p_matrix = np.random.random(size=x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = 0.4\n",
    "p_idx= (p_matrix <= prob)\n",
    "x[p_idx] = 1    # If there was 1 prev, no problem, but if there was a zero, map it to 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the toy-dataset\n",
    "filePath = '../data/Age50_DataExtract.csv'\n",
    "df = pd.read_csv(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['fyAGE', 'CCCfy98.1']\n",
    "df = df.drop(drop_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fy_list = col_list[:9]\n",
    "sy_list = col_list[9:]\n",
    "\n",
    "df_fy = df.filter(fy_list, axis=1)\n",
    "df_sy = df.filter(sy_list, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Saving the clean csv files\"\n",
    "\n",
    "fname_merge = '../data/Age50_DataExtract_merge.csv'\n",
    "fname_fy = '../data/Age50_DataExtract_fy.csv'\n",
    "fname_sy = '../data/Age50_DataExtract_sy.csv'\n",
    "\n",
    "df.to_csv(fname_merge, encoding='utf-8', index=False)\n",
    "df_fy.to_csv(fname_fy, encoding='utf-8', index=False)\n",
    "df_sy.to_csv(fname_sy, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tups = [tuple(x) for x in df.values]\n",
    "data_arr = np.asarray(tups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make multi valued discrete data into binary\n",
    "\n",
    "\n",
    "# converts column j to binary vec\n",
    "def convert_discrete_data(data, j):\n",
    "    # set of values\n",
    "    valset = set(data[:,j])\n",
    "    valdict = {}\n",
    "    count = 0\n",
    "    for i in valset:\n",
    "        valdict[i] = count\n",
    "        count += 1\n",
    "    \n",
    "    m = len(valset)\n",
    "    \n",
    "    # Now remap the data set\n",
    "    \n",
    "    N = data.shape[0]\n",
    "    \n",
    "    ndata = np.zeros((N,m))\n",
    "    \n",
    "    for i in range(N):\n",
    "        pos = valdict[data[i,j]]\n",
    "        ndata[i,pos] = 1 #one hot encoding\n",
    "    \n",
    "    new_arr = np.concatenate((data[:,:j], ndata, data[:,j+1:]), axis=1)\n",
    "    return new_arr\n",
    "                            \n",
    "\n",
    "\n",
    "nd = convert_discrete_data(data_arr,20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
